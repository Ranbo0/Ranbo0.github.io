<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!--pjax：防止跳转页面音乐暂停-->
  <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 

  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="〇、 什么是 CUDA CUDA（Compute Unified Device Architecture），是显卡厂商 NVIDIA 推出的运算平台。 CUDA™是一种由NVIDIA推出的通用 并行计算 架构，该架构使 GPU 架构，该架构使 GPU 能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员可以使用C语言来为CUDA™架构编写程序，所">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA beginning">
<meta property="og:url" content="http://example.com/2021/11/11/CUDA-beginning/index.html">
<meta property="og:site_name" content="曹行宇的Blog">
<meta property="og:description" content="〇、 什么是 CUDA CUDA（Compute Unified Device Architecture），是显卡厂商 NVIDIA 推出的运算平台。 CUDA™是一种由NVIDIA推出的通用 并行计算 架构，该架构使 GPU 架构，该架构使 GPU 能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员可以使用C语言来为CUDA™架构编写程序，所">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/CPU%20Arch.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/GPU%20Arch.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/sol.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/par.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/cuda1.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/thread.png">
<meta property="og:image" content="http://example.com/2021/11/11/CUDA-beginning/memory.png">
<meta property="article:published_time" content="2021-11-11T07:16:13.000Z">
<meta property="article:modified_time" content="2021-11-18T09:03:01.601Z">
<meta property="article:author" content="曹行宇">
<meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/11/11/CUDA-beginning/CPU%20Arch.png">

<link rel="canonical" href="http://example.com/2021/11/11/CUDA-beginning/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  
  
    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script src="/js/cursor/explosion.min.js"></script>
  

  <title>CUDA beginning | 曹行宇的Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
  <script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script>
  <div>
  <!--id="2316469703"是八方旅人音乐集-->
  <!--id="7066099170"是老音乐集-->
  <!--id="7068278359"是金碟豹-->
  <meting-js 
    server="netease"
    type="playlist"
    id="7068278359"
    fixed="true" 
    autoplay="true"
    loop="all"
    order="list"
    preload="auto"
    list-folded="ture"
    list-max-height="500px"
    volume="0.7"
    lrc-type="0">
  </meting-js>  
  </div>

  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">曹行宇的Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-guestbook">

    <a href="/guestbook/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>留言</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/11/CUDA-beginning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="曹行宇">
      <meta itemprop="description" content="摸鱼集团有限公司总裁">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="曹行宇的Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA beginning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-11-11 15:16:13" itemprop="dateCreated datePublished" datetime="2021-11-11T15:16:13+08:00">2021-11-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-18 17:03:01" itemprop="dateModified" datetime="2021-11-18T17:03:01+08:00">2021-11-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/11/11/CUDA-beginning/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/11/11/CUDA-beginning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="什么是-cuda">〇、 什么是 <code>CUDA</code></h1>
<p><code>CUDA</code>（<code>Compute Unified Device Architecture</code>），是显卡厂商 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/NVIDIA"><code>NVIDIA</code></a> 推出的运算平台。 CUDA™是一种由NVIDIA推出的通用 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/并行计算/113443">并行计算</a> 架构，该架构使 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/GPU"><code>GPU</code></a> 架构，该架构使 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/GPU"><code>GPU</code></a> 能够解决复杂的计算问题。 它包含了CUDA<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/指令集架构">指令集架构</a>（<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/ISA"><code>ISA</code></a>）以及GPU内部的并行计算引擎。 开发人员可以使用<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/C语言"><code>C</code>语言</a>来为<code>CUDA™</code>架构编写程序，所编写出的程序可以在支持<code>CUDA™</code>的处理器上以超高性能运行。</p>
<hr />
<span id="more"></span>
<h1 id="一-引言">一、 引言</h1>
<h2 id="gpu-的诞生">1.1 <code>GPU</code> 的诞生</h2>
<p>​ <code>CPU</code>的计算速度无法满足需求，大部分坐标处理工作及光影特效需要 <code>CPU</code> 亲自完成，占用太多运算时间，造成整体画面不能流畅的表现出来。随着时间的推移，<code>CPU</code> 进行各种光影计算的速度变得越来越无法满足游戏开发商的需求，更多特效的应用也几乎榨干了 <code>CPU</code> 的性能，因此，矛盾产生了，<code>GPU</code> 应运而生。</p>
<h2 id="gpu-概述">1.2 <code>GPU</code> 概述</h2>
<p><code>GPU</code>（<code>Graphics Processing Unit</code>）是一种特殊类型的处理器，具有数百或数千个内核，可并行运行大量计算。<code>GPU</code>是一种专门在<code>PC</code>，游戏机，手机等设备上上运行绘图运算工作的<a target="_blank" rel="noopener" href="https://baike.hk.xileso.top/baike-微處理器">微处理器</a>。虽然<code>GPU</code>在游戏中以<a target="_blank" rel="noopener" href="https://baike.hk.xileso.top/baike-3D渲染">3D</a><a target="_blank" rel="noopener" href="https://baike.hk.xileso.top/baike-3D渲染">渲染</a>而闻名，但它们对运行分析、<a target="_blank" rel="noopener" href="https://baike.hk.xileso.top/baike-深度学习">深度学习</a>和<a target="_blank" rel="noopener" href="https://baike.hk.xileso.top/baike-机器学习">机器学习</a>算法尤其有用。GPU允许某些计算比传统CPU上运行相同的计算速度快<code>10</code>倍至<code>100</code>倍。</p>
<h2 id="cuda-产生">1.3 <code>CUDA</code> 产生</h2>
<p><code>GPU</code>的高效在于可以高度并行处理。 以两个向量相加为例，<code>CPU</code>可能采取循环处理，每个循环对一个分量做加法。<code>GPU</code>则可以开多个线程，每个线程同时对一个分量做加法。<code>CPU</code>加法的速度一般快于<code>GPU</code>，但因为<code>GPU</code>可以同时开大量线程并行跑，因此更加高效。</p>
<p>为了降低<code>GPU</code>程序的开发难度，<code>NVIDIA</code>推出了 <code>CUDA</code>（<code>Compute Unified Device Architecture</code>，统一计算设备架构）这一编程模型。</p>
<h2 id="cpu-和-gpu-模型对比">1.4 <code>CPU</code> 和 <code>GPU</code> 模型对比</h2>
<h3 id="cpu-架构">1.4.1 <code>CPU</code> 架构</h3>
<p><img src="CPU%20Arch.png" /></p>
<p><code>CPU</code>（<code>Central Processing Unit</code>, 中央处理器）：<code>CPU</code>的结构主要包括运算器（<code>ALU</code>, <code>Arithmetic and Logic Unit</code>）、控制单元（<code>CU</code>, <code>Control Unit</code>）、寄存器（<code>Register</code>）、高速缓存器（<code>Cache</code>）等。简单来说就是<strong>计算单元，控制单元，存储单元</strong>。<strong>计算能力</strong>是CPU的很小的一部分功能。</p>
<ul>
<li><p><code>ALU</code> — 运算单元</p></li>
<li><p><code>Control</code> — 控制单元</p></li>
<li><p><code>Cache</code> — 高速缓存（<code>CPU</code>和内存之间的中介桥梁），进行高速数据交换的存储器</p></li>
<li><p><code>DRAM</code>— 进行短暂存储的存储器，易失性存储器（电源开启时数据存在，断开电源数据消失）</p></li>
</ul>
<p>可以看出 <code>CPU</code><strong>是基于低延迟设计</strong> 的。因为它有<strong>特别大的缓存空间可以降低延时</strong>，可以保存较多数据在缓存里面，当需要访问的这些数据时，只要在之前访问过的，现在直接在缓存里面取即可。</p>
<p>此外，<code>CPU</code>具有复杂的控制单元。例如当程序含有多个分支的时候，它可以通过提供分支预测的能力来降低延时。再比如在数据转发时，当一些指令依赖前面的指令结果时，数据转发的逻辑控制单元决定这些指令在<code>pipeline</code>中的位置并且尽可能快的转发一个指令的结果给后续的指令。这些动作需要很多的对比电路单元和转发电路单元。</p>
<p>因为<code>CPU</code>的架构中需要大量的空间去放置存储单元和控制单元，相比之下计算单元只占据了很小的一部分，所以它在大规模并行计算能力上极受限制，而更擅长于逻辑控制。</p>
<h3 id="gpu-架构">1.4.2 <code>GPU</code> 架构</h3>
<p><img src="GPU%20Arch.png" /></p>
<p><code>GPU</code>的结构里有大量的<code>ALU</code>（计算单元）单元和很少的<code>Cache</code>（缓存）。</p>
<p><code>GPU</code>的<code>Cache</code>不是像<code>CPU</code>那样保存后面需要访问的数据的，它是为<code>thread</code>（线程）提供服务的。如果有很多线程需要访问同一个相同的数据，缓存会合并这些访问，然后再去访问<code>dram</code>（因为需要访问的数据保存在<code>dram</code>中而不是<code>cache</code>里面），获取数据后<code>cache</code>会转发这个数据给对应的线程，这个时候<code>Cache</code>是作为数据转发的角色。但是由于需要访问<code>dram</code>，自然会带来延时的问题。</p>
<p><code>GPU</code>的工作大部分都计算量大，但没什么技术含量，而且要<strong>重复很多很多次</strong>。也就是说，<code>GPU</code>是用很多简单的计算单元去完成大量的计算任务，纯粹的人海战术。所以<code>GPU</code>的计算特点就是<strong>超长的流水线</strong>和<strong>并行计算</strong>。显然，<code>GPU</code>是基于高吞吐量设计的。</p>
<h2 id="串行计算和并行计算">1.5 串行计算和并行计算</h2>
<p>串行计算可以看成是将某个任务分解成一系列小任务，把这些小任务一一完成。在串行计算时，我们的想法就是让处理器每次处理一个计算任务，处理完一个计算任务后再计算下一个任务，直到所有小任务都完成了，那么这个大的程序任务也就完成了。<code>CPU</code> 的每个核心自身能力极强，处理任务上非常强悍，但是他核心少，所以 <code>CPU</code> 特别擅长串行计算。</p>
<p><img src="sol.png" /></p>
<p>当我们可以利用多核处理器同时处理多个任务时，为了进一步加快大任务的计算速度，我们可以把一些小任务分配到不同的处理器上进行同时计算，最后再将这些结果进行整合，完成一次任务计算。<code>GPU</code>的每个核心的计算能力不如<code>CPU</code>，但是它核心非常多，可同时处理多个计算任务，所以<code>GPU</code>擅长并行计算。</p>
<p><img src="par.png" /></p>
<p>所以，要加快程序的运行速度，可以先分析程序中哪些部分是强耦合的，哪些部分是相对独立的，对于强耦合的部分可以使用串行计算，而对于相对独立的部分，则可以充分利用多核处理器的优势进一步加速我们的计算任务，使用并行计算加快计算速度。因此，利用串行+并行的编程思路即可完成一次高性能计算，也就是充分利用<code>CPU</code>和<code>GPU</code>的优势来使程序性能得到优化。</p>
<h1 id="二-cuda-模型">二、 <code>CUDA</code> 模型</h1>
<h2 id="cuda-程序执行过程">2.1 <code>CUDA</code> 程序执行过程</h2>
<p>典型的<code>CUDA</code>程序实现流程如下：</p>
<ol type="1">
<li>把数据从<code>CPU</code>内存拷贝到<code>GPU</code>内存；</li>
<li>调用核函数对存储在<code>GPU</code>内存中的数据进行操作；</li>
<li>将数据从<code>GPU</code>内存传送到<code>CPU</code>内存。</li>
</ol>
<p><img src="cuda1.png" /></p>
<h2 id="cuda-线程模型">2.2 <code>CUDA</code> 线程模型</h2>
<p><code>kernel</code>在<code>device</code>上执行时实际上是启动很多线程，一个<code>kernel</code>所启动的所有线程称为一个网格（<code>grid</code>），同一个网格上的线程共享相同的全局内存空间，<code>grid</code>是线程结构的第一层次，而网格又可以分为很多线程块（<code>block</code>），一个线程块里面包含很多线程，这是第二个层次。</p>
<p><img src="thread.png" /></p>
<p>理想的主机端的串行代码只负责上一个<code>kernel</code>函数的清理和为下一个<code>kernel</code>函数进行准备，这样可以充分发挥<code>GPU</code>的高效运算能力，减少内存和显存之间传递数据的开销。但是在实践中一般无法将所有的计算任务交给设备端处理，主机端的串行代码中还应包含一些并行度较小的计算任务。</p>
<h2 id="cuda-内存模型">2.3 <code>CUDA</code> 内存模型</h2>
<p><code>CUDA</code>编程模型本质是从<code>GPU</code>架构中抽象出的一个内存层次结构，通过在<code>CUDA</code>上进行开发可以对<code>GPU</code>不同的内存层次进行处理。由于<code>LRC</code>码在编解码的过程中会进行数据的分组分割，需要对原始数据块进行存储处理等操作，为了加快<code>LRC</code>码的编解码性能，可以将分割分组后的数据存储到<code>GPU</code>的不同内存层次中去，这一点可以利用<code>CUDA</code>编程实现。因此，对于<code>CUDA</code>模型中不同的内存层次结构的了解很有必要。</p>
<p>在设备端全局内存类似于<code>CPU</code>的系统内存，具有存储空间大但是内存带宽低、时延较高的特点，而共享内存则类似于<code>CPU</code>的缓存，具有的存储空间比线程自带的寄存器空间要大且拥有高内存带宽以及低时延。其中，<code>GPU</code>的共享内存可以由<code>CUDA_C</code>的内核直接控制。</p>
<p><img src="memory.png" /></p>
<p>上图即为 <code>CUDA</code> 内存模型，前文已经介绍过 <code>Grid - Block - Thread</code> 的线程结构，在内存模型中，一个 <code>Grid</code> 中的所有 <code>Block</code> 的线程可以共享访问 <strong>全局内存</strong> 、 <strong>常量内存</strong> 、 <strong>纹理内存</strong> 的数据，在一个 <code>Block</code> 中，所有线程 <code>Thread</code> 可以共享访问 <strong>本地内存</strong> （<strong>共享内存</strong>）的数据。</p>
<h1 id="三-cuda-核函数">三、 <code>CUDA</code> 核函数</h1>
<p>假如我们要计算 <code>10000</code> 个 <code>0</code> 到 <code>9</code> 的随机数立方和，用 <code>C</code> 写应该是这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.c</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DATA_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// generate random number</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GenerateFunc</span><span class="params">(<span class="keyword">int</span>* dat, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        dat[i] = rand() % <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getRes</span><span class="params">(<span class="keyword">int</span>* dat, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        ret += dat[i] * dat[i] * dat[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    srand(time(<span class="literal">NULL</span>));</span><br><span class="line">    <span class="keyword">int</span> data[DATA_SIZE];</span><br><span class="line">    GenerateFunc(data, DATA_SIZE);</span><br><span class="line">    <span class="keyword">int</span> ret = getRes(data, DATA_SIZE);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ret = %d\n&quot;</span>, ret);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么我们如何让这个工作在显卡上完成呢？首先第一件事很显而易见，这些数字不能放在内存里了，而是要复制到<code>GPU</code>的显存上。</p>
<p>前文已经介绍过，在 <code>CUDA</code>的架构下，一个程序分为两个部份：<code>host</code>端和 <code>device</code>端。<code>Host</code>端是指在 <code>CPU</code>上执行的部份，而 <code>device</code>端则是在显示芯片上执行的部份。<code>Device</code>端的程序又称为 <code>kernel</code>。通常 <code>host</code>端程序会将数据准备好后，复制到显卡的内存中，再由显示芯片执行 <code>device</code>端程序，完成后再由 <code>host</code>端程序将结果从显卡的内存中取回。</p>
<p>我们需要把产生的数据复制到<code>Device</code>端的<code>RAM</code>，才能在显卡上完成计算，因此我们首先开辟一块合适的显存，然后把随机数从内存复制进去。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*把数据复制到显卡内存中*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>* gpudata, *result;</span><br><span class="line"></span><br><span class="line"><span class="comment">//cudaMalloc 取得一块显卡内存 ( 其中result用来存储计算结果 )</span></span><br><span class="line">cudaMalloc((<span class="keyword">void</span>**)&amp;gpudata, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)* DATA_SIZE);</span><br><span class="line">cudaMalloc((<span class="keyword">void</span>**)&amp;result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//cudaMemcpy 将产生的随机数复制到显卡内存中 </span></span><br><span class="line"><span class="comment">//cudaMemcpyHostToDevice - 从内存复制到显卡内存</span></span><br><span class="line"><span class="comment">//cudaMemcpyDeviceToHost - 从显卡内存复制到内存</span></span><br><span class="line">cudaMemcpy(gpudata, data, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)* DATA_SIZE,cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure>
<p><code>cudaMalloc</code>和 <code>cudaMemcpy</code>的用法和一般的 <code>malloc</code>及 <code>memcpy</code>类似，不过 <code>cudaMemcpy</code>则多出一个参数，指示复制内存的方向。在这里因为是从主内存复制到显卡内存，所以使用 <code>cudaMemcpyHostToDevice</code>。如果是从显卡内存到主内存，则使用<code>cudaMemcpyDeviceToHost</code>。</p>
<p>完成了从内存到显存的数据拷贝之后，我们接下来就要在显卡上完成计算了。</p>
<p><code>CUDA</code> 核函数就是要写在显示芯片上执行的程序。在 <code>CUDA</code>中，在函数前面加上<code>__global__</code> 表示这个函式是要在显示芯片上执行的,所以我们只要在正常函数之前加上一个<code>__global__</code>就行了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getRes</span><span class="params">(<span class="keyword">int</span>* dat, <span class="keyword">int</span>* res)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; DATA_SIZE; i++) &#123;</span><br><span class="line">        sum += dat[i] * dat[i] * dat[i];</span><br><span class="line">    &#125;</span><br><span class="line">    *res = sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，在 <code>C</code> 源代码中该接口是以 <code>int</code> 型返回的，但是这里的返回值是 <code>void</code> ，需要注意，所有在 <code>device</code> 端执行的代码，即前缀包含 <code>__global__</code> 的接口必须以 <code>void</code> 返回，也就是无返回值，所有需要返回的数据都要在参数列表中以参数的形式传入和修改。</p>
<p>写好核函数之后需要让<code>CUDA</code>执行这个函数。在 <code>CUDA</code>中，要执行一个核函数，使用以下的语法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">functionName&lt;&lt;&lt;blockNum, threadNum, shared_memory_size&gt;&gt;&gt;(args...);</span><br></pre></td></tr></table></figure>
<p>例如，我们令 <code>block</code> 数量为 <code>1</code> ，每个 <code>block</code> 中的 <code>thread</code> 数量为 <code>1</code>，不使用共享内存，则调用核函数的接口的方式为：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getRes&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>&gt;&gt;&gt;(gpudata, result);</span><br></pre></td></tr></table></figure>
<p>很显然，令 <code>block</code> 数量为 <code>1</code> ，每个 <code>block</code> 中的 <code>thread</code> 数量为 <code>1</code>，不使用共享内存，这样的话就是单纯的让单个线程完成计算，没有涉及到多线程并行计算。计算完了，千万别忘了还要<strong>把结果从显示芯片复制回主内存上</strong>，然后<strong>释放掉内存</strong>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum;</span><br><span class="line"></span><br><span class="line"><span class="comment">//cudaMemcpy -- copy result from device to host</span></span><br><span class="line">cudaMemcpy(&amp;sum, result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line"><span class="comment">//Free memory</span></span><br><span class="line">cudaFree(gpudata);</span><br><span class="line">cudaFree(result);</span><br></pre></td></tr></table></figure>
<p>完整程序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="comment">//CUDA RunTime API</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DATA_SIZE 10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> data[DATA_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GenerateFunc</span><span class="params">(<span class="keyword">int</span>* dat, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        dat[i] = rand() % <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//CUDA 初始化</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">InitCUDA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> count;</span><br><span class="line">    <span class="comment">//取得支持Cuda的装置的数目</span></span><br><span class="line">    cudaGetDeviceCount(&amp;count);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (count == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;There is no device.\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</span><br><span class="line">        cudaDeviceProp prop;</span><br><span class="line">        <span class="keyword">if</span> (cudaGetDeviceProperties(&amp;prop, i) == cudaSuccess) &#123;</span><br><span class="line">            <span class="keyword">if</span> (prop.major &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i == count) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;There is no device supporting CUDA 1.x.\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cudaSetDevice(i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getRes</span><span class="params">(<span class="keyword">int</span>* dat, <span class="keyword">int</span>* res)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; DATA_SIZE; i++) &#123;</span><br><span class="line">        sum += dat[i] * dat[i] * dat[i];</span><br><span class="line">    &#125;</span><br><span class="line">    *res = sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//CUDA 初始化</span></span><br><span class="line">    <span class="keyword">if</span> (!InitCUDA()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GenerateNumbers(data, DATA_SIZE);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>* gpudata, *result;</span><br><span class="line">    cudaMalloc((<span class="keyword">void</span>**)&amp;gpudata, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)* DATA_SIZE);</span><br><span class="line">    cudaMalloc((<span class="keyword">void</span>**)&amp;result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(gpudata, data, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)* DATA_SIZE, cudaMemcpyHostToDevice);</span><br><span class="line">    sumOfSquares &lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>&gt;&gt;&gt;(gpudata, result);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> sum;</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(&amp;sum, result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    cudaFree(gpudata);</span><br><span class="line">    cudaFree(result);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;GPU result: %d\n&quot;</span>, sum);</span><br><span class="line"></span><br><span class="line">    sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; DATA_SIZE; i++) &#123;</span><br><span class="line">        sum += data[i] * data[i] * data[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;CPU result: %d\n&quot;</span>, sum);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="四-核函数运行参数">四、 核函数运行参数</h1>
<p>上一个部分介绍了核函数的一种调用形式：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">functionName&lt;&lt;&lt;blockNum, threadNum, shared_memory_size&gt;&gt;&gt;(args...);</span><br></pre></td></tr></table></figure>
<p>其中 <code>&lt;&lt;&lt; &gt;&gt;&gt;</code> 标识了核函数的启动方式。实际上，当我们定义了核函数，并将其标识为 <code>__global__</code> 后：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(param1, ...)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>在主机端调用时应采用如下的形式：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;(param1, ...);</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>Dg</code> 是 <code>dim3</code> 类型的， <code>dim3</code> 即基于 <code>unsigned int</code> 定义的矢量类型，实质上是 <code>3</code> 个 <code>unsigned int</code> 组成的结构体，用来定义 <code>grid</code> 的维度和尺寸，即 <code>grid</code> 每行有 <code>Dg.x</code> 个 <code>block</code> ，每列有 <code>Dg.y</code> 个 <code>block</code> ，高度为 <code>Dg.z</code> ；</li>
<li><code>Db</code> 是 <code>dim3</code> 类型的，用来定义 <code>block</code> 的维度和尺寸，即 <code>block</code> 每行有 <code>Db.x</code> 个 <code>thread</code> ，每列有 <code>Db.y</code> 个 <code>thread</code> ，高度为 <code>Db.z</code> ；</li>
<li><code>Ns</code>： <code>size_t</code> 类型，可缺省，默认为 <code>0</code> 。 用于设置每个 <code>block</code> 除了静态分配的共享内存外，最多能动态分配的共享内存大小，单位为 <code>byte</code> 。 <code>0</code> 表示不需要动态分配；</li>
<li><code>S</code>： <code>cudaStream_t</code> 类型，可缺省，默认为 <code>0</code> 。 表示该核函数位于哪个流。</li>
</ul>
<p>前面已经介绍了 <code>GPU</code> 的线程结构，结合之前的线程结构更容易理解。</p>
<h2 id="核函数举例之矢量相加">4.1 核函数举例之矢量相加</h2>
<h3 id="一维-grid-一维-block">4.1.1 一维 <code>grid</code> ，一维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G1_B1</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 1-dim</span></span><br><span class="line">    <span class="comment">// block -- 1-dim</span></span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="一维-grid-二维-block">4.1.2 一维 <code>grid</code> ，二维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G1_B2</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 1-dim</span></span><br><span class="line">    <span class="comment">// block -- 2-dim</span></span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x * blockDim.y + threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="一维-grid-三维-block">4.1.3 一维 <code>grid</code> ，三维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G1_B2</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 1-dim</span></span><br><span class="line">    <span class="comment">// block -- 3-dim</span></span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x * blockDim.y * blockDim.z</span><br><span class="line">            + threadIdx.z * blockDim.y * blockDim.x</span><br><span class="line">            + threadIdx.y * blockDim.x</span><br><span class="line">            + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="二维-grid-一维-block">4.1.4 二维 <code>grid</code> ，一维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G2_B1</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 2-dim</span></span><br><span class="line">    <span class="comment">// block -- 1-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * blockDim.x + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="二维-grid-二维-block">4.1.5 二维 <code>grid</code> ，二维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G2_B2</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 2-dim</span></span><br><span class="line">    <span class="comment">// block -- 2-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * (blockDim.x * blockDim.y) + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="二维-grid-三维-block">4.1.6 二维 <code>grid</code> ，三维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G2_B3</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 2-dim</span></span><br><span class="line">    <span class="comment">// block -- 3-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * (blockDim.x * blockDim.y * blockDim.z)</span><br><span class="line">            + threadIdx.z * (blockDim.y * blockDim.x)</span><br><span class="line">            + threadIdx.y * blockDim.x</span><br><span class="line">            + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三维-grid-一维-block">4.1.7 三维 <code>grid</code> ，一维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G3_B1</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 3-dim</span></span><br><span class="line">    <span class="comment">// block -- 1-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.z * gridDim.x * gridDim.y + blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * blockDim.x + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三维-grid-二维-block">4.1.8 三维 <code>grid</code> ，二维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G3_B2</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 3-dim</span></span><br><span class="line">    <span class="comment">// block -- 2-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.z * gridDim.x * gridDim.y + blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * (blockDim.x * blockDim.y) + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三维-grid-三维-block">4.1.9 三维 <code>grid</code> ，三维 <code>block</code></h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G3_B3</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 3-dim</span></span><br><span class="line">    <span class="comment">// block -- 3-dim</span></span><br><span class="line">    <span class="keyword">int</span> bid = blockIdx.z * gridDim.x * gridDim.y + blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    <span class="keyword">int</span> tid = bid * (blockDim.x * blockDim.y * blockDim.z)</span><br><span class="line">            + threadIdx.z * (blockDim.y * blockDim.x)</span><br><span class="line">            + threadIdx.y * blockDim.x</span><br><span class="line">            + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="任务调度">4.2 任务调度</h2>
<p>以上面的 <code>addKernel_G1_B1</code> 为例：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel_G1_B1</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// grid  -- 1-dim</span></span><br><span class="line">    <span class="comment">// block -- 1-dim</span></span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    ret[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">addKernel_G1_B1&lt;&lt;&lt;<span class="number">1</span>, size&gt;&gt;&gt;(dev, dev_a, dev_b);</span><br></pre></td></tr></table></figure>
<p>当 <code>size &gt; 1024</code> 时，矢量会过长，因为一个 <code>block</code> 能容纳的线程数至多为 <code>1024</code> 。于是我们可以采用多个线程块来解决线程不足的问题。 假如我们设定每个线程块包含 <code>128</code> 个线程，则需要的线程块的数量为 <code>size / 128</code> 。 为了避免不能整除带来的问题，我们可以稍微多开一点 <code>(size + 127) / 128</code> ，但需要增加判断条件来避免越界。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b, <span class="keyword">const</span> <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; size)</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 运行核函数，运行设置为多个block，每个block中128个线程</span></span><br><span class="line">addKernel &lt;&lt;&lt;(size + <span class="number">127</span>) / <span class="number">128</span>, <span class="number">128</span> &gt;&gt;&gt;(dev, dev_a, dev_b, size);</span><br></pre></td></tr></table></figure>
<p>如果数据量大于 <code>Block_num * Thread_num</code>，那么我们就无法为每个分量单独分配一个线程了。 不过，一个简单的解决办法就是在核函数中增加循环。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addKernel</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">const</span> <span class="keyword">int</span>* a, <span class="keyword">const</span> <span class="keyword">int</span>* b, <span class="keyword">const</span> <span class="keyword">int</span> size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x; </span><br><span class="line">    <span class="keyword">while</span> (tid &lt; size)</span><br><span class="line">    &#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        <span class="comment">// 偏移分量等于一个Grid中包含的线程数量</span></span><br><span class="line">        tid += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 运行核函数，运行设置为1个Grid包含128个block，每个block包含128个线程</span></span><br><span class="line"><span class="comment">// 其中已经假设 size &gt; 128*128</span></span><br><span class="line">addKernel&lt;&lt;&lt;<span class="number">128</span>, <span class="number">128</span>&gt;&gt;&gt;(dev, dev_a, dev_b, size);</span><br></pre></td></tr></table></figure>
<h2 id="线程同步">4.3 线程同步</h2>
<p>同一个 <code>Block</code> 中的线程可以访问一块共享内存。由于共享内存缓冲区驻留在物理 <code>GPU</code> 上（片上内存），而不是 <code>GPU</code> 之外的系统内存（片外内存）上，因此访问共享内存的延迟要远远低于访问普通缓冲区的延迟。</p>
<p>不同 <code>Block</code> 之间存在隔离，如果我们需要不同线程之间进行通信，那么还需要考虑线程同步的问题。比如线程<code>1</code> 将某个数值写入内存，然后线程 <code>2</code> 会对该数值进行一些操作，那么显然必须等 <code>1</code> 完成之后 <code>2</code> 才可以操作，如果没有同步，程序将会因进入“竞态条件”而产生意想不到的错误。</p>
<p>举个栗子：</p>
<p>求向量点积，如四维向量的点积为： <span class="math display">\[
(x_1, x_2, x_3, x_4)\cdot (y_1, y_2, y_3, y_4)=x_1y_1 + x_2y_2 + x_3y_3 + x_4y_4
\]</span> 现在假设进行点积运算的两个向量的长度为 <code>33 * 1024</code> ，使用 <code>32</code> 个线程块，每个线程块使用 <code>256</code> 个线程。</p>
<h3 id="step-1.-申请共享内存">Step 1. 申请共享内存</h3>
<p>首先申请共享内存，例如申请一个数组 <code>cache</code> ：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="keyword">int</span> cache[threadsPerBlock];</span><br></pre></td></tr></table></figure>
<p>我们需要明白的是，一旦这样声明数组，就会创建与线程块的数量相同的数组 <code>cache</code> ，即每个线程块都会对应一个这样的数组 <code>cache</code> 。我们都知道，共享内存是用于同一个线程块内的线程之间交流的，不同线程块之间是无法通过共享内存进行交流的。另外，数组 <code>cache</code> 的大小是每个线程块中线程的个数，即线程块的大小。</p>
<h3 id="step-2.-分析每个线程的工作">Step 2. 分析每个线程的工作</h3>
<p>如果向量长度不是特别长(假设大小等于总线程个数)的话，每个线程只需要工作一次，即计算两个元素的积并保存在中间变量 <code>temp</code> 里。但是实际计算过程中由于向量长度过长，一次计算可能会计算不完，每个线程需要多次计算才能完成所有工作，因此 <code>temp</code> 保存的值可能为多个元素乘积之和。</p>
<p>假设数组大小为 <code>16</code> ，线程总数为 <code>4</code> 。此时一次并行是无法完成工作的，所以需要多次并行，即每个线程需要做四次工作才可完成计算。</p>
<p>那么相应的代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (tid &lt; N) &#123;</span><br><span class="line">    tmp += a[tid] * b[tid];</span><br><span class="line">    tid += blockDim.x * gridDim.x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你已经理解了上面这个过程，那么你也应该会明白每个线程块移动的步长为什么是总线程的个数了，即 <code>tid += blockDim.x * gridDim.x</code> 这段代码。</p>
<h3 id="step-3.-多线程协同">Step 3. 多线程协同</h3>
<p>要让多线程协同工作，就需要使用到共享内存。每个线程将 <code>tmp</code> 的值保存到每个线程块的共享内存( <code>shared memory</code> )中，即数组 <code>cache</code> 中：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cache[cacheIdx] = tmp;</span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure>
<p>这样每个线程块中对应的数组 <code>cache</code> 保存的就是每个线程的计算结果。为了节省带宽，这里又采用了并行计算中常用的归约算法，来计算数组中所有值之和，并保存在第一个元素( <code>cache[0]</code> )内。这样每个线程就通过共享内存( <code>shared memory</code> )进行数据交流了。具体代码如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//归约算法将每个线程块上的cache数组归约为一个值cache[0]，最终保存在数组c里</span></span><br><span class="line"><span class="keyword">int</span> i = blockDim.x /<span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span> (i != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (cacheIndex &lt; i) &#123;</span><br><span class="line">        cache[cacheIndex] += cache[cacheIndex + i];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    i /= <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="step-4.-保存结果">Step 4. 保存结果</h3>
<p>现在每个线程块的计算结果已经保存到每个共享数组 <code>cache</code> 的第一个元素 <code>cache[0]</code> 中，这样可以大大节省带宽。下面就需要将这些归约结果保存到全局内存( <code>global memory</code> )中。</p>
<p>观察核函数你会发现有一个传入参数——数组 <code>ret</code> 。这个数组是位于全局内存中，每次使用线程块中线程 <code>ID</code> 为 <code>0</code> 的线程来将每个线程块的归约结果保存到该数组中，注意这里每个线程块中的结果保存到数组 <code>ret</code> 中与之相对应的位置，即 <code>c[blockIdx.x]</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (cacheIdx == <span class="number">0</span>) &#123;</span><br><span class="line">    ret[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="step-5.-完整代码">Step 5. 完整代码</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cuda_runtime.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">33</span> * <span class="number">1024</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> blocksPerGrid = <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// kernel</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">dot</span><span class="params">(<span class="keyword">int</span>* ret, <span class="keyword">int</span>* a, <span class="keyword">int</span>* b)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="keyword">int</span> cache[threadsPerBlock];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> cacheIdx = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (tid &lt; N) &#123;</span><br><span class="line">        tmp += a[tid] * b[tid];</span><br><span class="line">        tid += gridDim.x * blockDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cache[cacheIdx] = tmp;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// int i = threadsPerBlock / 2;</span></span><br><span class="line">    <span class="keyword">int</span> i = blockDim.x / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span> (i != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cacheIdx &lt; i) &#123;</span><br><span class="line">            cache[cacheIdx] += cache[cacheIdx + i];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        i /= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (cacheIdx == <span class="number">0</span>) &#123;</span><br><span class="line">        ret[blockIdx.x] = cache[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// main</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>* a = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">int</span>* b = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">int</span>* ret = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(blocksPerGrid * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// initialize a and b</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        a[i] = <span class="number">1</span>;</span><br><span class="line">        b[i] = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span>* dev_a = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">int</span>* dev_b = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">int</span>* dev_ret = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="keyword">void</span>**)&amp;dev_a, N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="keyword">void</span>**)&amp;dev_b, N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="keyword">void</span>**)&amp;dev_ret, blocksPerGrid * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// CPU -&gt; GPU(host -&gt; device)</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(dev_a, a, N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(dev_b, b, N * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// kernel calculate</span></span><br><span class="line">    dot&lt;&lt;&lt;<span class="number">32</span>, <span class="number">256</span>&gt;&gt;&gt;(dev_ret, dev_a, dev_b);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// GPU -&gt; CPU(device -&gt; host)</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(ret, dev_ret, blocksPerGrid * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">1</span>; i &lt; blocksPerGrid; ++i) &#123;</span><br><span class="line">        ret[<span class="number">0</span>] += ret[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;The answer is : &quot;</span> &lt;&lt; ret[<span class="number">0</span>] &lt;&lt; std::endl;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// free memory</span></span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_a);</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_b);</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_ret);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        <div class="reward-container">
  <div>Buy me a coffee.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechat.jpg" alt="曹行宇 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="曹行宇 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CUDA/" rel="tag"># CUDA</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/11/11/octopath/" rel="prev" title="八方旅人 -- 壁纸 (1920×1080)">
      <i class="fa fa-chevron-left"></i> 八方旅人 -- 壁纸 (1920×1080)
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-cuda"><span class="nav-number">1.</span> <span class="nav-text">〇、 什么是 CUDA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80-%E5%BC%95%E8%A8%80"><span class="nav-number">2.</span> <span class="nav-text">一、 引言</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#gpu-%E7%9A%84%E8%AF%9E%E7%94%9F"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 GPU 的诞生</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gpu-%E6%A6%82%E8%BF%B0"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 GPU 概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-%E4%BA%A7%E7%94%9F"><span class="nav-number">2.3.</span> <span class="nav-text">1.3 CUDA 产生</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu-%E5%92%8C-gpu-%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94"><span class="nav-number">2.4.</span> <span class="nav-text">1.4 CPU 和 GPU 模型对比</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cpu-%E6%9E%B6%E6%9E%84"><span class="nav-number">2.4.1.</span> <span class="nav-text">1.4.1 CPU 架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gpu-%E6%9E%B6%E6%9E%84"><span class="nav-number">2.4.2.</span> <span class="nav-text">1.4.2 GPU 架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%B2%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%92%8C%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97"><span class="nav-number">2.5.</span> <span class="nav-text">1.5 串行计算和并行计算</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C-cuda-%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">二、 CUDA 模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 CUDA 程序执行过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 CUDA 线程模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 CUDA 内存模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89-cuda-%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-number">4.</span> <span class="nav-text">三、 CUDA 核函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B-%E6%A0%B8%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E5%8F%82%E6%95%B0"><span class="nav-number">5.</span> <span class="nav-text">四、 核函数运行参数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0%E4%B8%BE%E4%BE%8B%E4%B9%8B%E7%9F%A2%E9%87%8F%E7%9B%B8%E5%8A%A0"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 核函数举例之矢量相加</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4-grid-%E4%B8%80%E7%BB%B4-block"><span class="nav-number">5.1.1.</span> <span class="nav-text">4.1.1 一维 grid ，一维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4-grid-%E4%BA%8C%E7%BB%B4-block"><span class="nav-number">5.1.2.</span> <span class="nav-text">4.1.2 一维 grid ，二维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4-grid-%E4%B8%89%E7%BB%B4-block"><span class="nav-number">5.1.3.</span> <span class="nav-text">4.1.3 一维 grid ，三维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4-grid-%E4%B8%80%E7%BB%B4-block"><span class="nav-number">5.1.4.</span> <span class="nav-text">4.1.4 二维 grid ，一维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4-grid-%E4%BA%8C%E7%BB%B4-block"><span class="nav-number">5.1.5.</span> <span class="nav-text">4.1.5 二维 grid ，二维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4-grid-%E4%B8%89%E7%BB%B4-block"><span class="nav-number">5.1.6.</span> <span class="nav-text">4.1.6 二维 grid ，三维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4-grid-%E4%B8%80%E7%BB%B4-block"><span class="nav-number">5.1.7.</span> <span class="nav-text">4.1.7 三维 grid ，一维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4-grid-%E4%BA%8C%E7%BB%B4-block"><span class="nav-number">5.1.8.</span> <span class="nav-text">4.1.8 三维 grid ，二维 block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4-grid-%E4%B8%89%E7%BB%B4-block"><span class="nav-number">5.1.9.</span> <span class="nav-text">4.1.9 三维 grid ，三维 block</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 任务调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 线程同步</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#step-1.-%E7%94%B3%E8%AF%B7%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-number">5.3.1.</span> <span class="nav-text">Step 1. 申请共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step-2.-%E5%88%86%E6%9E%90%E6%AF%8F%E4%B8%AA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-number">5.3.2.</span> <span class="nav-text">Step 2. 分析每个线程的工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step-3.-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8D%8F%E5%90%8C"><span class="nav-number">5.3.3.</span> <span class="nav-text">Step 3. 多线程协同</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step-4.-%E4%BF%9D%E5%AD%98%E7%BB%93%E6%9E%9C"><span class="nav-number">5.3.4.</span> <span class="nav-text">Step 4. 保存结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#step-5.-%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="nav-number">5.3.5.</span> <span class="nav-text">Step 5. 完整代码</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">曹行宇</p>
  <div class="site-description" itemprop="description">摸鱼集团有限公司总裁</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Ranbo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Ranbo" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:605139189@qq.com" title="E-Mail → mailto:605139189@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://1.116.35.228/" title="friend-link → http:&#x2F;&#x2F;1.116.35.228&#x2F;" rel="noopener" target="_blank"><i class="fa fa-link fa-fw"></i>friend-link</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">曹行宇</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="true"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Ue2F9jwR42wMybrVdVDwcVhD-gzGzoHsz',
      appKey     : 'XpNd5pFh6jiikfByEeLtqgxG',
      placeholder: "快来给我留言，麻溜的",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

    </div>
</body>
</html>
